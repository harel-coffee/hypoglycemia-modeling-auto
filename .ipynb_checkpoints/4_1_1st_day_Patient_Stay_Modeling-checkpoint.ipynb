{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1EiNc4SZIZ6",
    "outputId": "1343be9c-b505-4986-9f60-b3390c0c5cff"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Compare Algorithms\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pgPyV6ODQYi0"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDbIj2MXuS_D"
   },
   "source": [
    "\n",
    "* try optimizing using the new function\n",
    "* add insulin dose as predictor variable\n",
    "* create a new cohort with the slopes in between the prior glucose and try it\n",
    "* use SMOTE for generating more training data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u1IDuT-Ea3lA"
   },
   "outputs": [],
   "source": [
    "name = '1stday-pred'\n",
    "\n",
    "base_dir =  './'\n",
    "\n",
    "full_df = pd.read_csv('GCP_output.csv')\n",
    "full_df['Y'] = (full_df['labresult'] < 72).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "ggzatr_nLX_h",
    "outputId": "f1cf7cf5-a5e2-472a-eee9-87a42157e117"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>admissionWeight</th>\n",
       "      <th>admissionheight</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>African American</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Asian</th>\n",
       "      <th>BMI</th>\n",
       "      <th>apachescore</th>\n",
       "      <th>gcs_avg</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>diabetes_t2</th>\n",
       "      <th>diabetes_t1</th>\n",
       "      <th>DKA_binary</th>\n",
       "      <th>hypo_obs</th>\n",
       "      <th>glu_min</th>\n",
       "      <th>glu_last</th>\n",
       "      <th>ALT (SGPT)</th>\n",
       "      <th>AST (SGOT)</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Hct</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>PT</th>\n",
       "      <th>PTT</th>\n",
       "      <th>RDW</th>\n",
       "      <th>WBC x 1000</th>\n",
       "      <th>albumin</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>lactate</th>\n",
       "      <th>pH</th>\n",
       "      <th>platelets x 1000</th>\n",
       "      <th>potassium</th>\n",
       "      <th>sodium</th>\n",
       "      <th>total bilirubin</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>spo2</th>\n",
       "      <th>nibp_systolic</th>\n",
       "      <th>nibp_diastolic</th>\n",
       "      <th>nibp_mean</th>\n",
       "      <th>temperature</th>\n",
       "      <th>insulin_binary</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>180.3</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.732803</td>\n",
       "      <td>70.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>8.90</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.280</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>233.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>38.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>92.3</td>\n",
       "      <td>180.3</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.392932</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>37.740833</td>\n",
       "      <td>19.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>27.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.650</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>36.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>190.5</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.555611</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.320755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>15.60</td>\n",
       "      <td>11.70000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>13.70</td>\n",
       "      <td>10.90</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>27.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>159.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>156.6</td>\n",
       "      <td>165.1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.451002</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.499132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>11.30</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>37.740833</td>\n",
       "      <td>14.50</td>\n",
       "      <td>7.60</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>31.5</td>\n",
       "      <td>97.5</td>\n",
       "      <td>0.815</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4200</td>\n",
       "      <td>286.5</td>\n",
       "      <td>4.60</td>\n",
       "      <td>135.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>113.9</td>\n",
       "      <td>172.7</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.189067</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>8.00</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>37.740833</td>\n",
       "      <td>15.40</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>33.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.110</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>288.0</td>\n",
       "      <td>4.90</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>36.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72048</th>\n",
       "      <td>128174</td>\n",
       "      <td>55.4</td>\n",
       "      <td>165.1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.324301</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13.499132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.40000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>17.85</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>116.5</td>\n",
       "      <td>0.795</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.3245</td>\n",
       "      <td>193.0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>141.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72049</th>\n",
       "      <td>128175</td>\n",
       "      <td>58.4</td>\n",
       "      <td>121.9</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.301166</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>19.10</td>\n",
       "      <td>8.40</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.740</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.2800</td>\n",
       "      <td>186.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>36.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72050</th>\n",
       "      <td>128176</td>\n",
       "      <td>78.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.653433</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>13.90</td>\n",
       "      <td>9.95</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.070</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>103.5</td>\n",
       "      <td>36.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72051</th>\n",
       "      <td>128177</td>\n",
       "      <td>102.0</td>\n",
       "      <td>177.8</td>\n",
       "      <td>73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.265371</td>\n",
       "      <td>158.0</td>\n",
       "      <td>10.193548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>10.75</td>\n",
       "      <td>11.35000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>14.15</td>\n",
       "      <td>23.70</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>102.5</td>\n",
       "      <td>2.515</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.2275</td>\n",
       "      <td>218.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72052</th>\n",
       "      <td>128178</td>\n",
       "      <td>83.9</td>\n",
       "      <td>185.4</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.408579</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.20</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>37.740833</td>\n",
       "      <td>16.30</td>\n",
       "      <td>15.30</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>20.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2.210</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>183.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>36.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72053 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  admissionWeight  admissionheight  age  gender  Caucasian  \\\n",
       "0               0             73.9            180.3   68     1.0        1.0   \n",
       "1               3             92.3            180.3   59     1.0        1.0   \n",
       "2               4            100.0            190.5   67     1.0        1.0   \n",
       "3               6            156.6            165.1   59     0.0        1.0   \n",
       "4              14            113.9            172.7   81     1.0        1.0   \n",
       "...           ...              ...              ...  ...     ...        ...   \n",
       "72048      128174             55.4            165.1   50     0.0        0.0   \n",
       "72049      128175             58.4            121.9   79     0.0        0.0   \n",
       "72050      128176             78.4            162.6   79     0.0        1.0   \n",
       "72051      128177            102.0            177.8   73     1.0        0.0   \n",
       "72052      128178             83.9            185.4   81     1.0        1.0   \n",
       "\n",
       "       African American  Hispanic  Asian        BMI  apachescore    gcs_avg  \\\n",
       "0                   0.0       0.0    0.0  22.732803         70.0  15.000000   \n",
       "1                   0.0       0.0    0.0  28.392932         28.0  15.000000   \n",
       "2                   0.0       0.0    0.0  27.555611         36.0  14.320755   \n",
       "3                   0.0       0.0    0.0  57.451002         55.0  13.499132   \n",
       "4                   0.0       0.0    0.0  38.189067         45.0  15.000000   \n",
       "...                 ...       ...    ...        ...          ...        ...   \n",
       "72048               1.0       0.0    0.0  20.324301         52.0  13.499132   \n",
       "72049               1.0       0.0    0.0  39.301166         21.0   9.000000   \n",
       "72050               0.0       0.0    0.0  29.653433         54.0  14.900000   \n",
       "72051               1.0       0.0    0.0  32.265371        158.0  10.193548   \n",
       "72052               0.0       0.0    0.0  24.408579         35.0  15.000000   \n",
       "\n",
       "       diabetes  diabetes_t2  diabetes_t1  DKA_binary  hypo_obs  glu_min  \\\n",
       "0           1.0            0            0         0.0       0.0    109.0   \n",
       "1           0.0            0            0         0.0       0.0    121.0   \n",
       "2           1.0            0            0         0.0       0.0    125.0   \n",
       "3           1.0            0            0         0.0       0.0    129.0   \n",
       "4           0.0            0            0         0.0       0.0    120.0   \n",
       "...         ...          ...          ...         ...       ...      ...   \n",
       "72048       0.0            0            0         0.0       0.0    121.0   \n",
       "72049       1.0            0            0         0.0       0.0     73.0   \n",
       "72050       0.0            0            0         0.0       0.0    139.0   \n",
       "72051       1.0            0            0         0.0       1.0     55.0   \n",
       "72052       0.0            0            0         0.0       0.0    137.0   \n",
       "\n",
       "       glu_last  ALT (SGPT)  AST (SGOT)   BUN   Hct    Hgb        PT  \\\n",
       "0         109.0        20.0        24.0  31.0  27.4   8.90  17.39987   \n",
       "1         121.0        30.0        25.0   8.0  31.0   9.90  17.39987   \n",
       "2         155.0        30.0        25.0  13.0  44.2  15.60  11.70000   \n",
       "3         195.0        30.0        25.0  14.5  35.5  11.30  17.39987   \n",
       "4         120.0        30.0        25.0  26.0  25.7   8.00  17.39987   \n",
       "...         ...         ...         ...   ...   ...    ...       ...   \n",
       "72048     129.0         9.0        20.0   7.5  26.0   8.25  10.40000   \n",
       "72049      75.0        36.0        31.0  51.0  22.0   6.90  11.50000   \n",
       "72050     139.0        12.0        18.0  32.0  39.0  13.50  12.60000   \n",
       "72051     108.0       272.0       264.0  30.5  31.5  10.75  11.35000   \n",
       "72052     156.0        30.0        25.0  45.0  29.0   9.20  17.39987   \n",
       "\n",
       "             PTT    RDW  WBC x 1000   albumin  bicarbonate  chloride  \\\n",
       "0      24.000000  16.00       14.10  2.300000         16.0     107.0   \n",
       "1      37.740833  19.10        4.10  2.864102         27.0     111.0   \n",
       "2      29.000000  13.70       10.90  2.864102         27.0     101.0   \n",
       "3      37.740833  14.50        7.60  2.864102         31.5      97.5   \n",
       "4      37.740833  15.40        6.90  2.864102         33.0     105.0   \n",
       "...          ...    ...         ...       ...          ...       ...   \n",
       "72048  21.000000  17.85        8.20  2.800000         20.0     116.5   \n",
       "72049  26.000000  19.10        8.40  3.000000         29.0     100.0   \n",
       "72050  59.000000  13.90        9.95  3.500000         27.0     101.0   \n",
       "72051  22.500000  14.15       23.70  3.300000         20.5     102.5   \n",
       "72052  37.740833  16.30       15.30  2.864102         20.0     117.0   \n",
       "\n",
       "       creatinine  glucose  lactate      pH  platelets x 1000  potassium  \\\n",
       "0           2.280    165.0      1.3  7.4000             233.0       3.70   \n",
       "1           0.650    121.0      1.0  7.4000              84.0       3.85   \n",
       "2           0.710    156.0      1.0  7.4000             159.0       3.80   \n",
       "3           0.815    196.0      1.0  7.4200             286.5       4.60   \n",
       "4           1.110    120.0      1.0  7.4000             288.0       4.90   \n",
       "...           ...      ...      ...     ...               ...        ...   \n",
       "72048       0.795    144.0      1.0  7.3245             193.0       4.85   \n",
       "72049       5.740     77.0      1.0  7.2800             186.0       5.00   \n",
       "72050       1.070    139.0      1.0  7.4000             130.0       3.60   \n",
       "72051       2.515    187.0      9.8  7.2275             218.5       3.70   \n",
       "72052       2.210    156.0      1.3  7.4000             183.0       5.70   \n",
       "\n",
       "       sodium  total bilirubin  heartrate   spo2  nibp_systolic  \\\n",
       "0       135.0              0.4       82.0   98.0          107.0   \n",
       "1       142.0              1.0       95.0   95.0          114.0   \n",
       "2       137.0              1.0       97.0   94.0          122.0   \n",
       "3       135.5              1.0       85.5   98.0          141.0   \n",
       "4       139.0              1.0      102.0   97.0          114.0   \n",
       "...       ...              ...        ...    ...            ...   \n",
       "72048   141.5              0.2       67.5  100.0          110.0   \n",
       "72049   136.0              0.4       70.0  100.0          166.0   \n",
       "72050   140.0              0.7       92.0   95.0          138.0   \n",
       "72051   141.0              0.5       71.0   99.0          135.5   \n",
       "72052   141.0              1.0       81.0   99.0          118.0   \n",
       "\n",
       "       nibp_diastolic  nibp_mean  temperature  insulin_binary  Y  \n",
       "0                57.0       76.5        38.15               0  0  \n",
       "1                58.0       83.0        36.90               0  0  \n",
       "2                70.0       89.0        36.70               0  0  \n",
       "3                72.0       99.0        36.45               0  0  \n",
       "4                64.5       84.0        36.75               0  0  \n",
       "...               ...        ...          ...             ... ..  \n",
       "72048            58.0       79.0        37.20               0  0  \n",
       "72049            72.0      104.0        36.90               0  0  \n",
       "72050            79.0      103.5        36.80               0  0  \n",
       "72051            71.5       96.5        33.00               0  1  \n",
       "72052            65.0       77.0        36.40               0  0  \n",
       "\n",
       "[72053 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = full_df.drop(['labresult'], axis = 1)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZigJa4G3ofw",
    "outputId": "e19cfb32-af6a-4cd8-db35-1b8312136a75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0.0\n",
       "admissionWeight     0.0\n",
       "admissionheight     0.0\n",
       "age                 0.0\n",
       "gender              0.0\n",
       "Caucasian           0.0\n",
       "African American    0.0\n",
       "Hispanic            0.0\n",
       "Asian               0.0\n",
       "BMI                 0.0\n",
       "apachescore         0.0\n",
       "gcs_avg             0.0\n",
       "diabetes            0.0\n",
       "diabetes_t2         0.0\n",
       "diabetes_t1         0.0\n",
       "DKA_binary          0.0\n",
       "hypo_obs            0.0\n",
       "glu_min             0.0\n",
       "glu_last            0.0\n",
       "ALT (SGPT)          0.0\n",
       "AST (SGOT)          0.0\n",
       "BUN                 0.0\n",
       "Hct                 0.0\n",
       "Hgb                 0.0\n",
       "PT                  0.0\n",
       "PTT                 0.0\n",
       "RDW                 0.0\n",
       "WBC x 1000          0.0\n",
       "albumin             0.0\n",
       "bicarbonate         0.0\n",
       "chloride            0.0\n",
       "creatinine          0.0\n",
       "glucose             0.0\n",
       "lactate             0.0\n",
       "pH                  0.0\n",
       "platelets x 1000    0.0\n",
       "potassium           0.0\n",
       "sodium              0.0\n",
       "total bilirubin     0.0\n",
       "heartrate           0.0\n",
       "spo2                0.0\n",
       "nibp_systolic       0.0\n",
       "nibp_diastolic      0.0\n",
       "nibp_mean           0.0\n",
       "temperature         0.0\n",
       "insulin_binary      0.0\n",
       "Y                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.isna().mean().round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9RxXuV4Ugk5",
    "outputId": "e3cb8bdd-0225-4785-a423-adefb99903aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'admissionWeight', 'admissionheight', 'age', 'gender',\n",
       "       'Caucasian', 'African American', 'Hispanic', 'Asian', 'BMI',\n",
       "       'apachescore', 'gcs_avg', 'diabetes', 'diabetes_t2', 'diabetes_t1',\n",
       "       'DKA_binary', 'hypo_obs', 'glu_min', 'glu_last', 'ALT (SGPT)',\n",
       "       'AST (SGOT)', 'BUN', 'Hct', 'Hgb', 'PT', 'PTT', 'RDW', 'WBC x 1000',\n",
       "       'albumin', 'bicarbonate', 'chloride', 'creatinine', 'glucose',\n",
       "       'lactate', 'pH', 'platelets x 1000', 'potassium', 'sodium',\n",
       "       'total bilirubin', 'heartrate', 'spo2', 'nibp_systolic',\n",
       "       'nibp_diastolic', 'nibp_mean', 'temperature', 'insulin_binary', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-t7nYFddPf_y"
   },
   "outputs": [],
   "source": [
    "model_df = full_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "ZekG9-Cd5rdy",
    "outputId": "2b4750d2-4ef5-4c81-8e7e-3d707066d0cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>admissionWeight</th>\n",
       "      <th>admissionheight</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>African American</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Asian</th>\n",
       "      <th>BMI</th>\n",
       "      <th>apachescore</th>\n",
       "      <th>gcs_avg</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>diabetes_t2</th>\n",
       "      <th>diabetes_t1</th>\n",
       "      <th>DKA_binary</th>\n",
       "      <th>hypo_obs</th>\n",
       "      <th>glu_min</th>\n",
       "      <th>glu_last</th>\n",
       "      <th>ALT (SGPT)</th>\n",
       "      <th>AST (SGOT)</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Hct</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>PT</th>\n",
       "      <th>PTT</th>\n",
       "      <th>RDW</th>\n",
       "      <th>WBC x 1000</th>\n",
       "      <th>albumin</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>glucose</th>\n",
       "      <th>lactate</th>\n",
       "      <th>pH</th>\n",
       "      <th>platelets x 1000</th>\n",
       "      <th>potassium</th>\n",
       "      <th>sodium</th>\n",
       "      <th>total bilirubin</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>spo2</th>\n",
       "      <th>nibp_systolic</th>\n",
       "      <th>nibp_diastolic</th>\n",
       "      <th>nibp_mean</th>\n",
       "      <th>temperature</th>\n",
       "      <th>insulin_binary</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>180.3</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.732803</td>\n",
       "      <td>70.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>8.90</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.280</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>233.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>38.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>92.3</td>\n",
       "      <td>180.3</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.392932</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>37.740833</td>\n",
       "      <td>19.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>27.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.650</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>36.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>190.5</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.555611</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.320755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>15.60</td>\n",
       "      <td>11.70000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>13.70</td>\n",
       "      <td>10.90</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>27.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>159.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>156.6</td>\n",
       "      <td>165.1</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.451002</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.499132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>11.30</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>37.740833</td>\n",
       "      <td>14.50</td>\n",
       "      <td>7.60</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>31.5</td>\n",
       "      <td>97.5</td>\n",
       "      <td>0.815</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4200</td>\n",
       "      <td>286.5</td>\n",
       "      <td>4.60</td>\n",
       "      <td>135.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>113.9</td>\n",
       "      <td>172.7</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.189067</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>8.00</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>37.740833</td>\n",
       "      <td>15.40</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>33.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.110</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>288.0</td>\n",
       "      <td>4.90</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>36.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72048</th>\n",
       "      <td>128174</td>\n",
       "      <td>55.4</td>\n",
       "      <td>165.1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.324301</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13.499132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.40000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>17.85</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>116.5</td>\n",
       "      <td>0.795</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.3245</td>\n",
       "      <td>193.0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>141.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72049</th>\n",
       "      <td>128175</td>\n",
       "      <td>58.4</td>\n",
       "      <td>121.9</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.301166</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>19.10</td>\n",
       "      <td>8.40</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.740</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.2800</td>\n",
       "      <td>186.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>36.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72050</th>\n",
       "      <td>128176</td>\n",
       "      <td>78.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.653433</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>13.90</td>\n",
       "      <td>9.95</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.070</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>103.5</td>\n",
       "      <td>36.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72051</th>\n",
       "      <td>128177</td>\n",
       "      <td>102.0</td>\n",
       "      <td>177.8</td>\n",
       "      <td>73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.265371</td>\n",
       "      <td>158.0</td>\n",
       "      <td>10.193548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>10.75</td>\n",
       "      <td>11.35000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>14.15</td>\n",
       "      <td>23.70</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>102.5</td>\n",
       "      <td>2.515</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.2275</td>\n",
       "      <td>218.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>135.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72052</th>\n",
       "      <td>128178</td>\n",
       "      <td>83.9</td>\n",
       "      <td>185.4</td>\n",
       "      <td>81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.408579</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.20</td>\n",
       "      <td>17.39987</td>\n",
       "      <td>37.740833</td>\n",
       "      <td>16.30</td>\n",
       "      <td>15.30</td>\n",
       "      <td>2.864102</td>\n",
       "      <td>20.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2.210</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>183.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>36.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72053 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  admissionWeight  admissionheight  age  gender  Caucasian  \\\n",
       "0               0             73.9            180.3   68     1.0        1.0   \n",
       "1               3             92.3            180.3   59     1.0        1.0   \n",
       "2               4            100.0            190.5   67     1.0        1.0   \n",
       "3               6            156.6            165.1   59     0.0        1.0   \n",
       "4              14            113.9            172.7   81     1.0        1.0   \n",
       "...           ...              ...              ...  ...     ...        ...   \n",
       "72048      128174             55.4            165.1   50     0.0        0.0   \n",
       "72049      128175             58.4            121.9   79     0.0        0.0   \n",
       "72050      128176             78.4            162.6   79     0.0        1.0   \n",
       "72051      128177            102.0            177.8   73     1.0        0.0   \n",
       "72052      128178             83.9            185.4   81     1.0        1.0   \n",
       "\n",
       "       African American  Hispanic  Asian        BMI  apachescore    gcs_avg  \\\n",
       "0                   0.0       0.0    0.0  22.732803         70.0  15.000000   \n",
       "1                   0.0       0.0    0.0  28.392932         28.0  15.000000   \n",
       "2                   0.0       0.0    0.0  27.555611         36.0  14.320755   \n",
       "3                   0.0       0.0    0.0  57.451002         55.0  13.499132   \n",
       "4                   0.0       0.0    0.0  38.189067         45.0  15.000000   \n",
       "...                 ...       ...    ...        ...          ...        ...   \n",
       "72048               1.0       0.0    0.0  20.324301         52.0  13.499132   \n",
       "72049               1.0       0.0    0.0  39.301166         21.0   9.000000   \n",
       "72050               0.0       0.0    0.0  29.653433         54.0  14.900000   \n",
       "72051               1.0       0.0    0.0  32.265371        158.0  10.193548   \n",
       "72052               0.0       0.0    0.0  24.408579         35.0  15.000000   \n",
       "\n",
       "       diabetes  diabetes_t2  diabetes_t1  DKA_binary  hypo_obs  glu_min  \\\n",
       "0           1.0            0            0         0.0       0.0    109.0   \n",
       "1           0.0            0            0         0.0       0.0    121.0   \n",
       "2           1.0            0            0         0.0       0.0    125.0   \n",
       "3           1.0            0            0         0.0       0.0    129.0   \n",
       "4           0.0            0            0         0.0       0.0    120.0   \n",
       "...         ...          ...          ...         ...       ...      ...   \n",
       "72048       0.0            0            0         0.0       0.0    121.0   \n",
       "72049       1.0            0            0         0.0       0.0     73.0   \n",
       "72050       0.0            0            0         0.0       0.0    139.0   \n",
       "72051       1.0            0            0         0.0       1.0     55.0   \n",
       "72052       0.0            0            0         0.0       0.0    137.0   \n",
       "\n",
       "       glu_last  ALT (SGPT)  AST (SGOT)   BUN   Hct    Hgb        PT  \\\n",
       "0         109.0        20.0        24.0  31.0  27.4   8.90  17.39987   \n",
       "1         121.0        30.0        25.0   8.0  31.0   9.90  17.39987   \n",
       "2         155.0        30.0        25.0  13.0  44.2  15.60  11.70000   \n",
       "3         195.0        30.0        25.0  14.5  35.5  11.30  17.39987   \n",
       "4         120.0        30.0        25.0  26.0  25.7   8.00  17.39987   \n",
       "...         ...         ...         ...   ...   ...    ...       ...   \n",
       "72048     129.0         9.0        20.0   7.5  26.0   8.25  10.40000   \n",
       "72049      75.0        36.0        31.0  51.0  22.0   6.90  11.50000   \n",
       "72050     139.0        12.0        18.0  32.0  39.0  13.50  12.60000   \n",
       "72051     108.0       272.0       264.0  30.5  31.5  10.75  11.35000   \n",
       "72052     156.0        30.0        25.0  45.0  29.0   9.20  17.39987   \n",
       "\n",
       "             PTT    RDW  WBC x 1000   albumin  bicarbonate  chloride  \\\n",
       "0      24.000000  16.00       14.10  2.300000         16.0     107.0   \n",
       "1      37.740833  19.10        4.10  2.864102         27.0     111.0   \n",
       "2      29.000000  13.70       10.90  2.864102         27.0     101.0   \n",
       "3      37.740833  14.50        7.60  2.864102         31.5      97.5   \n",
       "4      37.740833  15.40        6.90  2.864102         33.0     105.0   \n",
       "...          ...    ...         ...       ...          ...       ...   \n",
       "72048  21.000000  17.85        8.20  2.800000         20.0     116.5   \n",
       "72049  26.000000  19.10        8.40  3.000000         29.0     100.0   \n",
       "72050  59.000000  13.90        9.95  3.500000         27.0     101.0   \n",
       "72051  22.500000  14.15       23.70  3.300000         20.5     102.5   \n",
       "72052  37.740833  16.30       15.30  2.864102         20.0     117.0   \n",
       "\n",
       "       creatinine  glucose  lactate      pH  platelets x 1000  potassium  \\\n",
       "0           2.280    165.0      1.3  7.4000             233.0       3.70   \n",
       "1           0.650    121.0      1.0  7.4000              84.0       3.85   \n",
       "2           0.710    156.0      1.0  7.4000             159.0       3.80   \n",
       "3           0.815    196.0      1.0  7.4200             286.5       4.60   \n",
       "4           1.110    120.0      1.0  7.4000             288.0       4.90   \n",
       "...           ...      ...      ...     ...               ...        ...   \n",
       "72048       0.795    144.0      1.0  7.3245             193.0       4.85   \n",
       "72049       5.740     77.0      1.0  7.2800             186.0       5.00   \n",
       "72050       1.070    139.0      1.0  7.4000             130.0       3.60   \n",
       "72051       2.515    187.0      9.8  7.2275             218.5       3.70   \n",
       "72052       2.210    156.0      1.3  7.4000             183.0       5.70   \n",
       "\n",
       "       sodium  total bilirubin  heartrate   spo2  nibp_systolic  \\\n",
       "0       135.0              0.4       82.0   98.0          107.0   \n",
       "1       142.0              1.0       95.0   95.0          114.0   \n",
       "2       137.0              1.0       97.0   94.0          122.0   \n",
       "3       135.5              1.0       85.5   98.0          141.0   \n",
       "4       139.0              1.0      102.0   97.0          114.0   \n",
       "...       ...              ...        ...    ...            ...   \n",
       "72048   141.5              0.2       67.5  100.0          110.0   \n",
       "72049   136.0              0.4       70.0  100.0          166.0   \n",
       "72050   140.0              0.7       92.0   95.0          138.0   \n",
       "72051   141.0              0.5       71.0   99.0          135.5   \n",
       "72052   141.0              1.0       81.0   99.0          118.0   \n",
       "\n",
       "       nibp_diastolic  nibp_mean  temperature  insulin_binary  Y  \n",
       "0                57.0       76.5        38.15               0  0  \n",
       "1                58.0       83.0        36.90               0  0  \n",
       "2                70.0       89.0        36.70               0  0  \n",
       "3                72.0       99.0        36.45               0  0  \n",
       "4                64.5       84.0        36.75               0  0  \n",
       "...               ...        ...          ...             ... ..  \n",
       "72048            58.0       79.0        37.20               0  0  \n",
       "72049            72.0      104.0        36.90               0  0  \n",
       "72050            79.0      103.5        36.80               0  0  \n",
       "72051            71.5       96.5        33.00               0  1  \n",
       "72052            65.0       77.0        36.40               0  0  \n",
       "\n",
       "[72053 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C7QPuhe0qsCI",
    "outputId": "93175096-cee9-48a5-f877-48a7958a8e80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>66329.001434</td>\n",
       "      <td>67992.657893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admissionWeight</th>\n",
       "      <td>85.835857</td>\n",
       "      <td>81.125203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admissionheight</th>\n",
       "      <td>169.593967</td>\n",
       "      <td>168.041202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>64.131261</td>\n",
       "      <td>63.492012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.550140</td>\n",
       "      <td>0.500455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caucasian</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.721215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>African American</th>\n",
       "      <td>0.110852</td>\n",
       "      <td>0.166543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.033275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.014651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>284.554877</td>\n",
       "      <td>334.152492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apachescore</th>\n",
       "      <td>58.591821</td>\n",
       "      <td>67.746317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gcs_avg</th>\n",
       "      <td>13.536497</td>\n",
       "      <td>13.003765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.224872</td>\n",
       "      <td>0.348150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes_t2</th>\n",
       "      <td>0.032065</td>\n",
       "      <td>0.058108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes_t1</th>\n",
       "      <td>0.035433</td>\n",
       "      <td>0.069862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DKA_binary</th>\n",
       "      <td>0.021910</td>\n",
       "      <td>0.057032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypo_obs</th>\n",
       "      <td>0.064714</td>\n",
       "      <td>0.225147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glu_min</th>\n",
       "      <td>114.615921</td>\n",
       "      <td>100.237480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glu_last</th>\n",
       "      <td>141.491046</td>\n",
       "      <td>141.450790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT (SGPT)</th>\n",
       "      <td>58.543837</td>\n",
       "      <td>77.994206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST (SGOT)</th>\n",
       "      <td>76.565397</td>\n",
       "      <td>123.480010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUN</th>\n",
       "      <td>26.252103</td>\n",
       "      <td>32.371368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hct</th>\n",
       "      <td>33.193227</td>\n",
       "      <td>31.683722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hgb</th>\n",
       "      <td>10.966654</td>\n",
       "      <td>10.416174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>17.322703</td>\n",
       "      <td>17.731452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTT</th>\n",
       "      <td>37.833539</td>\n",
       "      <td>38.062805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RDW</th>\n",
       "      <td>15.289779</td>\n",
       "      <td>15.855985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBC x 1000</th>\n",
       "      <td>12.221868</td>\n",
       "      <td>13.016402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albumin</th>\n",
       "      <td>2.893302</td>\n",
       "      <td>2.758788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bicarbonate</th>\n",
       "      <td>24.258571</td>\n",
       "      <td>23.350898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chloride</th>\n",
       "      <td>104.341138</td>\n",
       "      <td>104.776446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine</th>\n",
       "      <td>1.496644</td>\n",
       "      <td>1.960353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>145.622841</td>\n",
       "      <td>152.875838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lactate</th>\n",
       "      <td>1.369921</td>\n",
       "      <td>1.722764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>7.520236</td>\n",
       "      <td>7.373670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelets x 1000</th>\n",
       "      <td>204.609926</td>\n",
       "      <td>204.022473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potassium</th>\n",
       "      <td>4.097363</td>\n",
       "      <td>4.140703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium</th>\n",
       "      <td>138.291270</td>\n",
       "      <td>138.441996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total bilirubin</th>\n",
       "      <td>1.075674</td>\n",
       "      <td>1.202818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartrate</th>\n",
       "      <td>85.570425</td>\n",
       "      <td>87.748779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spo2</th>\n",
       "      <td>97.176116</td>\n",
       "      <td>97.534476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nibp_systolic</th>\n",
       "      <td>120.910058</td>\n",
       "      <td>117.495199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nibp_diastolic</th>\n",
       "      <td>64.915977</td>\n",
       "      <td>62.762809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nibp_mean</th>\n",
       "      <td>80.819371</td>\n",
       "      <td>78.314806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>36.837968</td>\n",
       "      <td>36.773614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin_binary</th>\n",
       "      <td>0.164760</td>\n",
       "      <td>0.222912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y                            0             1\n",
       "Unnamed: 0        66329.001434  67992.657893\n",
       "admissionWeight      85.835857     81.125203\n",
       "admissionheight     169.593967    168.041202\n",
       "age                  64.131261     63.492012\n",
       "gender                0.550140      0.500455\n",
       "Caucasian             0.788235      0.721215\n",
       "African American      0.110852      0.166543\n",
       "Hispanic              0.029297      0.033275\n",
       "Asian                 0.012456      0.014651\n",
       "BMI                 284.554877    334.152492\n",
       "apachescore          58.591821     67.746317\n",
       "gcs_avg              13.536497     13.003765\n",
       "diabetes              0.224872      0.348150\n",
       "diabetes_t2           0.032065      0.058108\n",
       "diabetes_t1           0.035433      0.069862\n",
       "DKA_binary            0.021910      0.057032\n",
       "hypo_obs              0.064714      0.225147\n",
       "glu_min             114.615921    100.237480\n",
       "glu_last            141.491046    141.450790\n",
       "ALT (SGPT)           58.543837     77.994206\n",
       "AST (SGOT)           76.565397    123.480010\n",
       "BUN                  26.252103     32.371368\n",
       "Hct                  33.193227     31.683722\n",
       "Hgb                  10.966654     10.416174\n",
       "PT                   17.322703     17.731452\n",
       "PTT                  37.833539     38.062805\n",
       "RDW                  15.289779     15.855985\n",
       "WBC x 1000           12.221868     13.016402\n",
       "albumin               2.893302      2.758788\n",
       "bicarbonate          24.258571     23.350898\n",
       "chloride            104.341138    104.776446\n",
       "creatinine            1.496644      1.960353\n",
       "glucose             145.622841    152.875838\n",
       "lactate               1.369921      1.722764\n",
       "pH                    7.520236      7.373670\n",
       "platelets x 1000    204.609926    204.022473\n",
       "potassium             4.097363      4.140703\n",
       "sodium              138.291270    138.441996\n",
       "total bilirubin       1.075674      1.202818\n",
       "heartrate            85.570425     87.748779\n",
       "spo2                 97.176116     97.534476\n",
       "nibp_systolic       120.910058    117.495199\n",
       "nibp_diastolic       64.915977     62.762809\n",
       "nibp_mean            80.819371     78.314806\n",
       "temperature          36.837968     36.773614\n",
       "insulin_binary        0.164760      0.222912"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.groupby(\"Y\").mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uF2GeASm63ba",
    "outputId": "04abc8e7-a637-4b42-f54a-9590bdba0963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16766824420912385"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model_df[\"Y\"])/len(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCOWSaCj4eyo"
   },
   "source": [
    "# Creating Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RbeFHP9mbuRy"
   },
   "outputs": [],
   "source": [
    "#Add in stratify to ensure equal label distribution in test/train\n",
    "train, test, train_labels, test_labels = train_test_split(model_df.drop(['Y'], axis = 1),\n",
    "                                                          model_df['Y'],\n",
    "                                                          test_size=0.15,\n",
    "                                                          random_state=100, stratify = model_df['Y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5lz8ARRMsb0H"
   },
   "outputs": [],
   "source": [
    "pred_vars = train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37IsJxGPkMDb",
    "outputId": "9a193874-ae1b-48b9-ee15-7efa6a7a5f04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16767083027185892"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_labels)/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RMIAKarLxFM6"
   },
   "outputs": [],
   "source": [
    "smote = False\n",
    "\n",
    "if(smote):\n",
    "  train, train_labels = SMOTE().fit_resample(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aRu_J4w3tV4G"
   },
   "outputs": [],
   "source": [
    "under = False\n",
    "\n",
    "if(under):\n",
    "\n",
    "  # Undersampling traning dataframe for majority class\n",
    "  train_tmp = train.copy()\n",
    "  train_tmp['Y'] = train_labels\n",
    "\n",
    "  # Downsample majority class\n",
    "  df_majority_downsampled = resample(train_tmp[train_tmp['Y'] == 0], \n",
    "                                  replace=False,    # sample without replacement\n",
    "                                  n_samples=len(train_tmp[train_tmp['Y'] == 1]),     # to match minority class\n",
    "                                  random_state=123) # reproducible results\n",
    "  \n",
    "  # Combine minority class with downsampled majority class\n",
    "  train = pd.concat([df_majority_downsampled, train_tmp[train_tmp['Y'] == 1]])\n",
    "  \n",
    "  # Display new class counts\n",
    "  print(train.Y.value_counts())\n",
    "  train_labels = train.Y\n",
    "  train = train.drop(columns=['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OMT1qZXuDpw",
    "outputId": "f4b20782-6478-4ebf-f40f-ec63dd5619e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Length: 61245\n",
      "Testing Dataset Length: 10808\n"
     ]
    }
   ],
   "source": [
    "print('Training Dataset Length: ' + str(len(train)))\n",
    "print('Testing Dataset Length: ' + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xxdk33XqsC3A",
    "outputId": "96e2ae7a-b391-4513-fc84-3ad9127cc7e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16767083027185892"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_labels)/len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_Z8Uo_34lWI"
   },
   "source": [
    "# Defining Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "d8-NTd2ala8p"
   },
   "outputs": [],
   "source": [
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0z0VIy2zap0C"
   },
   "outputs": [],
   "source": [
    "def grid_search_wrapper(clf, param_grid, refit_score='roc_auc'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "\n",
    "    scorers_list = ['roc_auc', 'accuracy', 'f1', 'precision', 'recall']\n",
    "\n",
    "    cross_val = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=cross_val, scoring= scorers_list, refit = refit_score, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(train, train_labels)\n",
    "\n",
    "    # make the predictions\n",
    "    y_probs = grid_search.predict_proba(test)[:,1]\n",
    "    y_pred = grid_search.predict(test)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print('Best Score for {} on Train Set: {}'.format(refit_score, grid_search.best_score_))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    results, results_prec, df_delta = performanceTest(test_labels, y_probs)\n",
    "\n",
    "    results_list.append(df_delta)\n",
    "\n",
    "    print('\\nResults on Test Set Prediction (min delta):')\n",
    "    for y in results.keys():\n",
    "      print(str(y) + ': ' + str(np.round(results[y], 4)))\n",
    "\n",
    "    print('\\nResults on Test Set Prediction (max precision):')\n",
    "    for y in results_prec.keys():\n",
    "      print(str(y) + ': ' + str(np.round(results_prec[y], 4)))\n",
    "\n",
    "    # print(roc_auc_score(test_labels, y_pred))\n",
    "    # print(recall_score(test_labels, y_pred))\n",
    "    # print(precision_score(test_labels, y_pred))\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(test_labels, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "      \n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YXo5iw7OanL5"
   },
   "outputs": [],
   "source": [
    "def performanceTest(realtarget,predictedtarget,verbose=False):\n",
    "  res = []\n",
    "  # Create list of threshold to be assessed\n",
    "  _, _, list_threshold = roc_curve(realtarget, predictedtarget)\n",
    "\n",
    "  # Calculate performance for each threshold\n",
    "  for thr in list_threshold:\n",
    "    p = np.copy(predictedtarget)\n",
    "  \n",
    "\n",
    "    # Get AUC\n",
    "    fpr, tpr, _ = roc_curve(realtarget, p)\n",
    "    auroc_p = auc(fpr, tpr)\n",
    "\n",
    "    # Classification\n",
    "    p[p < thr] = 0; # inferior\n",
    "    p[p != 0] = 1; # sup or equal\n",
    "\n",
    "    # Get AUPR\n",
    "    precision, recall, _ = precision_recall_curve(realtarget, p)\n",
    "    aupr_p = auc(recall, precision)\n",
    "\n",
    "    # Confusion matrix\n",
    "    matrix = confusion_matrix(realtarget, p)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(realtarget, p)\n",
    "    sens = recall_score(realtarget, p) # or recall\n",
    "    spec = matrix[0,0]/(matrix[0,0]+matrix[0,1]) # TN/TN+FP\n",
    "    pr = precision_score(realtarget, p)\n",
    "\n",
    "    df_tmp = pd.DataFrame({'Threshold': [thr], 'Accuracy': [acc],\n",
    "                           'Precision' : [pr],'Specificity': [spec],\n",
    "                           'Sensitivity': [sens],'AUC': [auroc_p],\n",
    "                           'AUPR': [aupr_p], 'Model' : curr_model})\n",
    "      \n",
    "    res.append(df_tmp)\n",
    "\n",
    "  # The next measures are not independent from the threshold.\n",
    "  res = pd.concat(res, axis=0)\n",
    "  res.index = pd.RangeIndex(start=0, stop=len(list_threshold), step=1)\n",
    "  \n",
    "  thr_delta = res.loc[(res.Sensitivity - res.Specificity).abs().idxmin()]\n",
    "  if verbose:\n",
    "    print('\\n')\n",
    "    print(f'Minimizing \\u0394(Sen-Spec): AUC={thr_delta.AUC:0.2f}')\n",
    "    print(f'Minimizing \\u0394(Sen-Spec): AUPR={thr_delta.AUPR:0.2f}')\n",
    "    print(f'Minimizing \\u0394(Sen-Spec): Sense={thr_delta.Sensitivity:0.2f}')\n",
    "    print(f'Minimizing \\u0394(Sen-Spec): Spec={thr_delta.Specificity:0.2f}')\n",
    "\n",
    "  thr_prec = res.loc[res.Precision.idxmax()]\n",
    "  score_loss = thr_delta.Sensitivity + thr_delta.Specificity\n",
    "\n",
    "  d_thr_delta =  dict(thr_delta)\n",
    "  del d_thr_delta['Model']\n",
    "  d_thr_prec = dict(thr_prec)\n",
    "  del d_thr_prec['Model']\n",
    "\n",
    "  \n",
    "  print(thr_delta)\n",
    "  return d_thr_delta, d_thr_prec, thr_delta\n",
    "  #return thr_delta.AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12eB5Ipo4pNY"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZbH7_2sUM41"
   },
   "source": [
    "Things to try:\n",
    "\n",
    "* SK Learn Feature Selection\n",
    "* Ensemble Models\n",
    "* Adding in Medication\n",
    "* Each Patient is only considered once, add a feature if they had a hypoglycemic event in previous patient stay\n",
    "* Minimum glucose during observation window, maybe std?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nTMlHZOL7s1w",
    "outputId": "da5c319c-9405-424d-db32-6361069b86ac"
   },
   "outputs": [],
   "source": [
    "curr_model = 'LogisticRegression'\n",
    "clf = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'], \n",
    "    'C' : [100, 10, 1.0, 0.1, 0.01],\n",
    "    'penalty': ['l2', 'l1']\n",
    "}\n",
    "\n",
    "grid_search = grid_search_wrapper(clf, param_grid)\n",
    "\n",
    "\n",
    "importance = grid_search.best_estimator_.fit(train, train_labels).coef_[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (40,8))\n",
    "plt.bar(np.arange(0, len(importance)), height = importance)\n",
    "plt.xticks(np.arange(0, len(importance)), labels = pred_vars, fontsize = 14, rotation = 'vertical')\n",
    "plt.title(\"Feature Importance for Log Reg Model\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(base_dir + 'LR feature importance.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGyCShoYYDju",
    "outputId": "c05799d1-390e-416e-d7ec-50a6db2d2870"
   },
   "outputs": [],
   "source": [
    "curr_model = 'Random Forest'\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [3, 5, 10], \n",
    "    'n_estimators' : [100, 200, 300],\n",
    "    'max_depth': [3, 5, 15, 25],\n",
    "    'max_features': [3, 5, 10, 20, 40]\n",
    "}\n",
    "\n",
    "results = grid_search_wrapper(clf, param_grid)\n",
    "\n",
    "importance = results.best_estimator_.fit(train, train_labels).feature_importances_\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (40,8))\n",
    "plt.bar(np.arange(0, len(importance)), height = importance)\n",
    "plt.xticks(np.arange(0, len(importance)), labels = pred_vars, fontsize = 10, rotation = 'vertical')\n",
    "plt.title(\"Feature Importance for RF Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(base_dir + 'RF feature importance.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5JOKFUo49yN"
   },
   "outputs": [],
   "source": [
    "curr_model = 'XGBoost'\n",
    "\n",
    "clf = XGBClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\"max_depth\": [6,15],\n",
    "              \"min_child_weight\" : [3,6],\n",
    "              \"n_estimators\": [200],\n",
    "              \"learning_rate\": [0.01,0.1,0.5],\n",
    "              \"colsample_bytree\": [0.5,0.7],\n",
    "              \"subsample\": [1],\n",
    "              \"max_delta_step\": [0.1,3,10],\n",
    "              \"colsample_bylevel\": [0.6, 0.7],\n",
    "              \"base_score\": [sum(train_labels)/len(train),0.1,0.5],\n",
    "              }\n",
    "\n",
    "results = grid_search_wrapper(clf, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qRAprkLligK"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import table \n",
    "results_df = pd.concat(results_list, axis=1)\n",
    "finaldf = results_df.T\n",
    "\n",
    "ax = plt.subplot(111, frame_on=False) # no visible frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "table(ax, finaldf)  # where df is your data frame\n",
    "plt.tight_layout()\n",
    "plt.savefig(base_dir + 'results_cv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtPZI21IpVCu"
   },
   "outputs": [],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_XdKTDloLdR"
   },
   "source": [
    "# Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jt4J-5PE2OPh"
   },
   "outputs": [],
   "source": [
    "def run_exps(X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame):\n",
    "  '''\n",
    "  Lightweight script to test many models and find winners\n",
    "  :param X_train: training split\n",
    "  :param y_train: training target vector\n",
    "  :param X_test: test split\n",
    "  :param y_test: test target vector\n",
    "  :return: DataFrame of predictions\n",
    "  '''\n",
    "  dfs = []\n",
    "  global models\n",
    "  models = [\n",
    " #           ('LinReg', LinearRegression()),\n",
    "            ('LogReg', LogisticRegression()), \n",
    "            ('RF', RandomForestClassifier())\n",
    "            # ,\n",
    "            # ('KNN', KNeighborsClassifier()),\n",
    "            # ('SVM', SVC(probability=True)), \n",
    "            # ('GNB', GaussianNB()),\n",
    "            # ('XGB', XGBClassifier()),\n",
    "            # ('AdaBoost', AdaBoostClassifier()),\n",
    "            # ('DecisionTree', DecisionTreeClassifier()),\n",
    "            # ('Bagging', BaggingClassifier()),\n",
    "            # ('GradientBoosting', GradientBoostingClassifier())\n",
    "          ]\n",
    "    \n",
    "  results = []\n",
    "  names = []\n",
    "  scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "  target_names = ['Control', 'Hypoglycemic']\n",
    "  probs = {}\n",
    "  for name, model in models:\n",
    "          kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=90210)\n",
    "          cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "          clf = model.fit(X_train, y_train)\n",
    "\n",
    "          y_pred = clf.predict(X_test)\n",
    "          y_probs = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "          print(name)\n",
    "          print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "          print(roc_auc_score(y_test, y_probs))\n",
    "          results.append(cv_results)\n",
    "          names.append(name)\n",
    "          this_df = pd.DataFrame(cv_results)\n",
    "          this_df['model'] = name\n",
    "          dfs.append(this_df)\n",
    "          probs[name] = y_probs\n",
    "  final = pd.concat(dfs, ignore_index=True)\n",
    "  \n",
    "\n",
    "  return final, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IO8hJMFm8VDN",
    "outputId": "422fabe5-3724-452b-ec4e-7a40534f3834"
   },
   "outputs": [],
   "source": [
    "final, probs = run_exps(train, train_labels, test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR5hBQW58Wk0"
   },
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "for model in list(set(final.model.values)):\n",
    "    df_t = final.loc[final.model == model]\n",
    "    #bootstrap = df_t.sample(n=30, replace=True)\n",
    "    #bootstraps.append(bootstrap)\n",
    "    bootstraps.append(df_t)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "\n",
    "## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2ajakDsDQOp"
   },
   "outputs": [],
   "source": [
    "results_long_nofit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAf-Y-Ab8XrJ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "sns.set(font_scale=2.5)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig(base_dir + 'benchmark_models_performance.png',dpi=300)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4.1 1st day Patient Stay Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
